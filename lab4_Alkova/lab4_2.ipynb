{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bda84b9e-b320-4e7b-a4a4-d75cb0df1879",
   "metadata": {},
   "source": [
    "Використання Pipeline для задачі заповнення тексту"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "54aaf4d8-c173-4ab5-8111-6c210f7cfc0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at youscan/ukr-roberta-base were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Слово:  квіти, Ймовірність: 0.2006\n",
      "Слово:  вишні, Ймовірність: 0.1415\n",
      "Слово:  дерева, Ймовірність: 0.0683\n",
      "Слово:  сосни, Ймовірність: 0.0468\n",
      "Слово:  рослини, Ймовірність: 0.0440\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Завантаження моделі\n",
    "fill_mask = pipeline(\"fill-mask\", model=\"youscan/ukr-roberta-base\")\n",
    "\n",
    "# Приклад тексту\n",
    "text = \"На городі ростуть <mask>.\"\n",
    "\n",
    "results = fill_mask(text)\n",
    "for result in results:\n",
    "    print(f\"Слово: {result['token_str']}, Ймовірність: {result['score']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004f4a0a-e168-4d77-8750-2909e64fe70c",
   "metadata": {},
   "source": [
    "Для генеративних моделей, таких як GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "258293b0-7785-4ca2-b6de-5e55c7c35cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Зацвіла яблуня у мене в саду. Вона вбралась у червоне намисто. Із саду вітер зірвав це намисто та й кинув у воду. Я в річку упала через ті намистинки, які в воду впали. Я заплакала дуже. Тато прийшов сюди, побачив\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "generator = pipeline(\"text-generation\", model=\"benjamin/gpt2-large-wechsel-ukrainian\")\n",
    "results = generator(\"Зацвіла яблуня\", max_length=60, num_return_sequences=1)\n",
    "\n",
    "for result in results:\n",
    "    print(result[\"generated_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2e43b4-35c2-4a46-90cf-b7e61c71cfb5",
   "metadata": {},
   "source": [
    "Використання для класифікації"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "11a871e0-c678-4f1b-8cc8-c8d8a9d72dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'disgust', 'score': 0.9209380149841309}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Завантаження багатомовної моделі\n",
    "classifier = pipeline(\"sentiment-analysis\", model=\"michellejieli/emotion_text_classifier\")\n",
    "text = \"pineapple pizza is the worst\"\n",
    "\n",
    "# Аналіз тональності\n",
    "result = classifier(text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00c4595-cdf6-4975-b834-b739cd79a0a2",
   "metadata": {},
   "source": [
    "Переклад"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7713955-53af-4982-8970-d62b0683851c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'translation_text': 'It snowed today'}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "translator = pipeline(\"translation_uk_to_en\", model=\"Helsinki-NLP/opus-mt-uk-en\")\n",
    "result = translator(\"Сьогодні випав сніг\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3397c93-adae-466d-b425-958b5493d236",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
